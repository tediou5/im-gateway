# 服务出口流量过大解决方法技术调研

Author: qians

Date: 2023/5/15

Version: v0.0.1

## 问题

目前在8核16G的服务器上, 处理性能(不推送, 只处理)为1300w. 每条消息平均长度为1K. 因此目标出口流量为13000000k, 约为13G/s. 远远超出了单张网卡处理能力.

## 解决方法

1. 挂载多网卡

各服务商提供的云服务器都可以将多张网卡挂载载一个服务器上, 以提高网络IO处理性能和吞吐量. 但这里有一个问题, 普通的配置多网卡不能将多张网卡配置在一个网段(每张网卡一个IP). 大家配置多网卡的一般需求是公网一张网卡处理公网流量, 内网一张网卡处理内部流量. 相互直接并不共通.
这明显不符合我们的需求.

2. Linux多网卡绑定技术Bond

在linux系统中, 提供了Bond工具. 利用Bond我们可以将多张网卡绑定为一个虚拟网卡, 共同处理一个IP网段的流量.
根据设置的模式的不同, 会有不同的分配和处理流量的行为:

- mode = 0 round-robin

此模式下, 多网卡会进行负载均衡. 流量会以轮训的方式选择一张网卡收发报文. 基于per packet方式发送, 即每张网卡各分配一个数据包, 此模式以非常朴素的方式增加了吞吐量, 且提供了网卡的容错能力.
但有一个缺陷: 该模式需要在交换机端上配置聚合口, 在cisco交换机上为: port channel.

- mode = 1 active-backup

此模式为主备模式: 一张网卡为主状态, 承载所有流量, 备状态的网卡不会有任何流量. 只有当主卡down掉时, 才会将备状态的卡切换至主状态.
此模式用于提高系统可用性, 与当前需求无关.

- mode = 2 load-balancing (xor)

此模式多网卡进行负载均衡. 流量通过目标源的mac和hash因子做xor(异或)算法来分配到一个固定的网卡. 此模式也可以满足我们的需求.
但此模式有2个缺陷:

  1. 该模式需要在交换机端上配置聚合口, 在cisco交换机上为: port channel.
  2. 若使用了代理, 例如nginx, 则目标源地址都是nginx服务器的地址, 那么所有流量依然会在同个网卡上, 无法达到负载均衡扩大吞吐量的效果.

- mode = 3 fault-tolerance

此模式下, 数据会进行广播, 即每个网卡都会冗余发送这份数据. 此模式更多用于金融系统中保证必达, 与我们的需求不符. 不考虑.

- mode = 4 802.3ad
