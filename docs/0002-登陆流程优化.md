- Feature: 登陆流程优化
- Start Date: 2023/6/5
- Version: 0.0.2
# Summary

用户登陆时, 连接层直接根据Token解析出Appid和Pin. 并通过kafka通知业务端. 业务端完成登陆后用户元数据(chats)也通过kafka传递给连接层.

# Motivation

目前当用户登陆时, 实际分为两部分.

1. 连接层接受登陆报文, 通过HTTP请求业务层, 业务层通过HTTP返回登陆结果和数据.
2. 连接层根据返回的pin和chats数据将该连接分配至莫线程上, 并更新users和chats. 完成登陆.

这里主要问题是HTTP请求会导致性能受影响且和业务端的绑定比较死. 不利于业务端进行分布式部署.

# Guide-level explanation

之所以之前如此设计. 实际上是由于当时认为在登陆时我无法获知用户的Pin(我只能获取到他的Token), 所以无法将该连接存放到users中. 也就没法处理接下来kafka传来的后续的数据.

但实际上我只需要和业务层协商好`secret key`就可以按照JWTs协议解析出Token中的Appid和Pin, 就可以更新Users并通过kafka正确的处理该连接后续的任务了.

当登录失败是, 会发送关闭重连的断开指令给前端, 让前端返回登录页.

## 优化后的登陆流程

优化后的登陆流程需要在推送协议中添加登陆(login)和登录失败(loginFailed)事件, 并分3步完成登陆:

1. 连接层接受登陆报文, 从Token中解析出Appid和Pin. 将该连接更新至users中. 此时实际上用户已经完成登陆了, 只是尚未更新该用户的chats数据, 还无法推送chat相关消息.
2. 通过kafka将用户登陆请求传递至业务层.
3. 业务端处理好用户登陆的请求后, 将chats通过login事件传递进连接层. 若失败则调用disconnect事件断开用户连接.

## 唯一ID生成

由于不同appid下pin可能重复, 因此pin需要和appid一起生产唯一id, 以供连接层使用.

```rust
{appId}:{userId}
```

## Kafka Topic

连接层推送至业务层是, 依然走im-session-link Topic. 将前端传来的消息直接推给业务端. 协议遵循`MessageProtocol`消息协议的Connect协议.

## 推送协议更新

若用户登录成功, 则调用Login事件, 将用户元数据(chats)传递至连接层. 若失败, 则调用Disconnect事件, 关闭该连接.

### login

| 参数名    | 参数类型      | 说明           | 是否必填 |
| --------- | ------------- | -------------- | -------- |
| trace_id  | u64           | 追踪id         | 是       |
| base_info | String        | baseInfo       | 是       |
| chats     | Vec\<String\> | 用户所属群列表 | 是       |

- example

    ```json
    [1, "baseinfo jsonstring", ["chat1", "chat2"]]
    ```

### loginFailed

| 参数名   | 参数类型 | 说明     | 是否必填 |
| -------- | -------- | -------- | -------- |
| trace_id | u64      | 追踪id   | 是       |
| reason   | String   | 断开原因 | 是       |

- example

    ```json
    [1, "auth failed"]
    ```

# Reference-level explanation

这里只阐述连接层的实现细节.

当用户连接后, 首先应该发送鉴权消息. 连接层根据token解析出appid和pin, 并将拼装出对应的唯一id. 之后根据唯一id将该连接转移至对应的线程, 并放置在`Unverified`数据结构中.
当业务端返回(kafka)后, 再将连接从Unverified中取出并执行相应处理.

```rust
struct InnerData {
    name: String,
    unverified: AHashMap<u64 /* trace_id */, (String /* appid:pin */, Platform)>,
    users: ahash::AHashMap<std::rc::Rc<String>, crate::linker::User>,
    chats: ahash::AHashMap<String, std::collections::HashSet<std::rc::Rc<String>>>,
    id_worker: crate::snowflake::SnowflakeIdWorkerInner,
}

fn process(&self, event: Event) {
    match event {
        Event::Connect(uid, platform) => {
            let trace_id = self.id_worker.next_id()?;
            self.unverified.insert(trace_id, (uid, platform));
            // TODO: procude into kafka.
        }
        Event::LoginFailed(trace_id, reason) => {
            if let Some((_, platform)) = self.unverified.remove(&trace_id) {
                platform.close(reason);
            };
        }
        Event::Login(trace_id, auth_message, chat_list) => {
            if let Some((uid, platform)) = self.unverified.remove(&trace_id) {
                let uid = std::rc::Rc::new(uid);
                let user_connection = self
                    .users
                    .entry(uid.clone())
                    .or_insert_with_key(|uid| crate::linker::User::from_pin(uid.clone()));
                let is_update = user_connection.update(crate::linker::Login{ platform, auth_message });
                if !is_update {
                   self._login_chats(uid, chat_list)
                }
            };
        }
        _ => todo!(),
    }
}
```

# Prior art

此方案属于后端逻辑的优化, 对前端是无影响的, 能够保证向前兼容性. 对业务层也反而是更加的友好了: 不需要单独使用HTTP来处理登陆, 与别的请求一同使用kafka进行交互.
但对于连接层, 切换至此方案需要做不小的改动, 但我认为这还是值得的.

# Future possibilities

1. 目前实现的方案中, 每次重连或切换账号都是建立新通道, 并没有做到连接复用
2. 目前判断一个请求是否是登录请求是通过解析第一条消息报文来做到的, 登录之后就不再解析报文了. 所以无法复用通道切换不同账号. 可能会再协议头中追加标识符来区分是否是连接报文.
